{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting midi_preproc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile midi_preproc.py\n",
    "\n",
    "from music21 import converter, stream, note, chord, duration, pitch\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "import os.path\n",
    "\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "instruments = ['Piano', 'Guitar', 'Violin']\n",
    "\n",
    "def midiToMatrix(filename):\n",
    "    if os.path.isfile(filename+'.prep') :\n",
    "        f = open(filename+'.prep', 'rb')\n",
    "        return pkl.load(f)\n",
    "    parsed = converter.parse(filename)\n",
    "\n",
    "    party = []\n",
    "\n",
    "    for part in parsed:\n",
    "        for voice in part.getElementsByClass(stream.Voice):\n",
    "            if voice.getInstrument().instrumentName in instruments:\n",
    "                for thisNote in [n for n in voice if (isinstance(n,note.Note) or isinstance(n,chord.Chord))]:\n",
    "                    cur_chord = np.zeros(129)\n",
    "                    for _pitch in thisNote.pitches:\n",
    "                        cur_chord[_pitch.midi] = 1\n",
    "                        #text += pitch.name+str(pitch.octave)\n",
    "                    dur = thisNote.duration.quarterLength\n",
    "                    cur_chord[-1] = dur#dur.numerator / float(dur.denominator)\n",
    "\n",
    "                    party.append(cur_chord)\n",
    "                    #text += dur_to_text(thisNote.duration.type)+'z'\n",
    "    res= csc_matrix(party) if len(party) > 0 else csc_matrix(np.zeros((0,129)))\n",
    "    with open(filename+'.prep', 'wb') as f:\n",
    "        pkl.dump(res,f)\n",
    "    return res;\n",
    "\n",
    "from music21 import midi\n",
    "\n",
    "def save_mat2_mid(mat, fname='output/test.mid'):\n",
    "    music_stream = stream.Stream()\n",
    "\n",
    "    for dense_line in np.array(mat):\n",
    "        (notes,) = np.where(dense_line[:-1]>0.5)\n",
    "\n",
    "        pitches = []\n",
    "        for n in notes:\n",
    "            pitches.append(pitch.Pitch(midi=n))\n",
    "\n",
    "        crd = chord.Chord(notes= pitches, quarterLength=np.round(dense_line[-1]*2048)/2048)\n",
    "        music_stream.append(crd)\n",
    "        \n",
    "    md = midi.translate.streamToMidiFile(music_stream)\n",
    "    md.open(fname, 'wb')\n",
    "    md.write()\n",
    "    md.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test\n",
    "sparsed = midiToMatrix('midi/abide_.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_mat2_mid(sparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataset_generation.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataset_generation.py\n",
    "\n",
    "SEQ_LEN = 200\n",
    "STRIDE_MU = 20 #expected value of stride\n",
    "STRIDE_SIG = 2 #standard standard deviation of stride\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from os import listdir\n",
    "from random import choice\n",
    "from midi_preproc import midiToMatrix\n",
    "import numpy as np\n",
    "import scipy\n",
    "from prefetch_generator import background\n",
    "import pickle as pkl\n",
    "\n",
    "import tqdm as tqdm\n",
    "def parallelization(fun,massive,tq = True):    \n",
    "    num_cores = 20#multiprocessing.cpu_count()\n",
    "    if tq:\n",
    "        results = np.array(Parallel(n_jobs=num_cores)(delayed(fun)(i) for i in tqdm(massive)))\n",
    "        return results\n",
    "    else:\n",
    "        results = Parallel(n_jobs=num_cores)(delayed(fun)(i) for i in massive)\n",
    "        return results\n",
    "\n",
    "bad_files = []\n",
    "\n",
    "if os.path.isfile('bad_files.pkl'):\n",
    "    with open('bad_files.pkl','rb') as f:\n",
    "        bad_files = pkl.load(f)\n",
    "\n",
    "#all files in storage\n",
    "files = [each for each in listdir('midi') if each.endswith('.mid') and (not ('midi/'+each in bad_files))]\n",
    "files_precomp = [each for each in files if os.path.isfile(\"midi/\"+each+'.prep')]\n",
    "\n",
    "\n",
    "def split_random_file(precomputed=False):#returns sparse matrix every SEQ_LEN rows of wich are cut from the vectorized midi file\n",
    "    fi = choice(files_precomp) if precomputed else choice(files)#select random midi file\n",
    "    \n",
    "    cut = []\n",
    "    \n",
    "    sparsed = midiToMatrix('midi/'+fi)\n",
    "    pos = 0\n",
    "    \n",
    "    #cut the sequence\n",
    "    while(sparsed.shape[0] - pos > SEQ_LEN):\n",
    "        \n",
    "        cut.append(sparsed[pos: pos+SEQ_LEN])\n",
    "        \n",
    "        pos+= np.clip(np.round(np.random.normal(STRIDE_MU, STRIDE_SIG)), 1, SEQ_LEN//2)\n",
    "    if len(cut) > 0:\n",
    "        return scipy.sparse.vstack(cut,format='csr')\n",
    "    else:\n",
    "        return scipy.sparse.csc_matrix(np.zeros(shape=(0,129)))\n",
    "    \n",
    "def generate_minibatch(batch_size=32, precomputed=True):\n",
    "    res = []\n",
    "    while(sum([x.shape[0] for x in res])/SEQ_LEN <= batch_size):\n",
    "        res.append(split_random_file(precomputed))\n",
    "    return scipy.sparse.vstack(res,format='csr')\n",
    "\n",
    "#@background(max_prefetch=10)\n",
    "def iterate_minibatches(num_batches, batch_size=32, precomputed=True):\n",
    "    for i in xrange(num_batches):\n",
    "        yield generate_minibatch(batch_size,precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset_generation import generate_minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rnd_cutter = split_random_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ress\n"
     ]
    }
   ],
   "source": [
    "test_generate = generate_minibatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8200x129 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 25189 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 133 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2110x129 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 5031 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "midi_preproc.midiToMatrix('midi/abide_.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "bad_files= []\n",
    "\n",
    "if os.path.isfile('bad_files.pkl'):\n",
    "    with open('bad_files.pkl','rb') as f:\n",
    "        bad_files = pkl.load(f)\n",
    "\n",
    "files = glob.glob('midi/*/*/*/*.mid')#[each for each in listdir('midi') if each.endswith('.mid') and (not ('midi/'+each in bad_files))]\n",
    "files = [each for each in files if not os.path.isfile(each+'.prep') and (not each in bad_files)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109275"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "import midi_preproc\n",
    "import signal\n",
    "\n",
    "def handler(signum, frame):\n",
    "    raise Exception(\"Execution timed out\")\n",
    "\n",
    "signal.signal(signal.SIGALRM, handler)\n",
    "    \n",
    "def preprocess(fname):\n",
    "    try:\n",
    "        signal.alarm(3.5*60)\n",
    "        res = midi_preproc.midiToMatrix(fname)\n",
    "        signal.alarm(0)\n",
    "        if res.shape[0] == 0:\n",
    "            return False, fname\n",
    "        del res\n",
    "        return True, fname\n",
    "    except BaseException:\n",
    "        signal.alarm(0)\n",
    "        return False, fname\n",
    "\n",
    "all_goods = 0\n",
    "\n",
    "\n",
    "\n",
    "for fname in tqdm_notebook(files):\n",
    "    good, _ = preprocess(fname)\n",
    "    if not good:\n",
    "        bad_files.append(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "import midi_preproc\n",
    "import signal\n",
    "\n",
    "def handler(signum, frame):\n",
    "    raise Exception(\"Execution timed out\")\n",
    "\n",
    "signal.signal(signal.SIGALRM, handler)\n",
    "    \n",
    "def preprocess(fname):\n",
    "    try:\n",
    "        signal.alarm(4*60)\n",
    "        res = midi_preproc.midiToMatrix(fname)\n",
    "        signal.alarm(0)\n",
    "        if res.shape[0] == 0:\n",
    "            return False, fname\n",
    "        del res\n",
    "        return True, fname\n",
    "    except BaseException:\n",
    "        signal.alarm(0)\n",
    "        return False, fname\n",
    "\n",
    "\n",
    "all_goods = 0\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(3,maxtasksperchild=1)\n",
    "    for good, fname in tqdm_notebook(p.imap_unordered(preprocess, files),total=len(files)):\n",
    "        if not good:\n",
    "            bad_files.append(fname)\n",
    "            if len(bad_files) % 10 == 9:\n",
    "                with open(\"bad_files.pkl\",'wb') as f:\n",
    "                    pkl.dump(bad_files, f)\n",
    "        else:\n",
    "            all_goods+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"bad_files.pkl\",'wb') as f:\n",
    "    pkl.dump(bad_files, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "1d95e25a5e1647c4a05c2e22d5fd6598": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "b8d13bcf21c54f18b00c9b1caf5861b8": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
