{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dataset_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_generation.SEQ_LEN = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GT 630M (CNMeM is enabled with initial size: 80.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from theano import sparse\n",
    "from lasagne.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMB_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_len = theano.shared(dataset_generation.SEQ_LEN)\n",
    "\n",
    "sequence = sparse.csc_fmatrix('input_seq')\n",
    "dur_seq = T.fvector('Duration sequence')\n",
    "d_s_resh = dur_seq.reshape((-1, seq_len))\n",
    "\n",
    "embedd_w = theano.shared(np.random.normal(0,0.001, (128, EMB_SIZE)))\n",
    "sequence_embedded = sparse.dot(sequence, embedd_w).reshape((-1, seq_len, EMB_SIZE))\n",
    "\n",
    "\n",
    "\n",
    "inputs = sequence_embedded[:,:-1]\n",
    "dur_inps = d_s_resh[:,:-1]\n",
    "\n",
    "targets = sequence.toarray().reshape((-1,seq_len,128))[:,1:]\n",
    "dur_targets = d_s_resh[:, 1:]\n",
    "\n",
    "l_input_sequence = InputLayer(shape=(None, None, EMB_SIZE),input_var=inputs)\n",
    "l_input_dur_sequence = InputLayer(shape=(None, None),input_var=dur_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet import Recurrence\n",
    "from lasagne.layers import *\n",
    "from agentnet.memory import *\n",
    "from agentnet.resolver import ProbabilisticResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "srng = RandomStreams(seed=234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###One step of rnn\n",
    "class step:\n",
    "    \n",
    "    #inputs\n",
    "    inp = InputLayer((None, EMB_SIZE),name='current embedded')\n",
    "    dur_inp = InputLayer((None,),name='current dur')\n",
    "    \n",
    "    c_prev = InputLayer((None,LSTM_SIZE),name='previous rnn cell')\n",
    "    h_prev = InputLayer((None,LSTM_SIZE),name='previous rnn state')\n",
    "    \n",
    "    c_new, h_new = LSTMCell(c_prev, h_prev,inp,name=\"LSTM\") #just concat -> denselayer\n",
    "    \n",
    "    next_token_probas = DenseLayer(h_new,128,nonlinearity=T.nnet.sigmoid)\n",
    "    next_dur_ = DenseLayer(h_new,1,nonlinearity=None)\n",
    "    next_dur = ReshapeLayer(next_dur_, (-1,))\n",
    "    \n",
    "    #pick next token from predicted probas\n",
    "    next_token = ExpressionLayer(next_token_probas,\n",
    "                    lambda probas: T.lt(srng.uniform(size=probas.shape), probas ).astype('float32')\n",
    "                                )\n",
    "    next_emb = DenseLayer(next_token, EMB_SIZE, W=embedd_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f57a4a05390>, <lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f57a4a056d0>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] You are giving Recurrence an input sequence of undefined length (None).\n",
      "Make sure it is always above <unspecified>(n_steps) you specified for recurrence\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    }
   ],
   "source": [
    "training_loop = Recurrence(\n",
    "    state_variables={step.h_new:step.h_prev, step.c_new:step.c_prev},\n",
    "    input_sequences={step.inp:l_input_sequence, step.dur_inp:l_input_dur_sequence},\n",
    "    tracked_outputs=[step.next_token_probas,step.next_dur],\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM.b_to_ingate, LSTM.W_previous rnn state_to_ingate, LSTM.W_current embedded_to_ingate, LSTM.b_to_forgetgate, LSTM.W_previous rnn state_to_forgetgate, LSTM.W_current embedded_to_forgetgate, LSTM.b_to_cell, LSTM.W_previous rnn state_to_cell, LSTM.W_current embedded_to_cell, LSTM.b_to_outgate, LSTM.W_previous rnn state_to_outgate, LSTM.W_current embedded_to_outgate, LSTM.W_cell_to_ingate_peephole.scales, LSTM.W_cell_to_forgetgate_peephole.scales, LSTM.W_cell_to_outgate_peephole.scales, W, b, W, b, W]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(training_loop,trainable=True)\n",
    "\n",
    "weights+= [embedd_w]\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = lasagne.layers.get_output(training_loop[step.next_token_probas])\n",
    "predicted_durs = lasagne.layers.get_output(training_loop[step.next_dur])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SKIP_LOSS = theano.shared(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iiinps = {sequence: notes.astype('float32'), dur_seq:durations.astype('float32')} #dbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loss_reg.eval(iiinps).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logprobs = T.log(predicted_probabilities)\n",
    "neglogprobs = T.log(1 - predicted_probabilities)\n",
    "durs = predicted_durs.reshape((-1,seq_len - 1))\n",
    "\n",
    "loss_categ = - targets* logprobs - (1-targets) * neglogprobs#binary crossentropy no need for \n",
    "loss_reg = lasagne.objectives.squared_error(dur_targets, durs)\n",
    "\n",
    "loss = loss_categ.sum(axis=-1).reshape((-1,)) + loss_reg.reshape((-1,))\n",
    "loss = loss.reshape((-1,seq_len - 1))[:,SKIP_LOSS:].mean()\n",
    "\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training\n",
    "train_step = theano.function([sequence, dur_seq], [loss_categ, loss_reg],\n",
    "                             updates=training_loop.get_automatic_updates()+updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_shape(step.next_dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] State_variables recommended type is OrderedDict.\n",
      "                Otherwise, order of agent state outputs from get_sessions and get_agent_reaction methods\n",
      "                may depend on python configuration.\n",
      "\n",
      "                Current order is: [<lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f57a4a05390>, <lasagne.layers.shape.ReshapeLayer object at 0x7f57a4a14050>, <lasagne.layers.merge.ElemwiseMergeLayer object at 0x7f57a4a056d0>, <lasagne.layers.dense.DenseLayer object at 0x7f57a4a14290>]\n",
      "                You may find OrderedDict in standard collections module: from collections import OrderedDict\n",
      "                \n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    }
   ],
   "source": [
    "n_steps = T.scalar(dtype='int32')\n",
    "feedback_loop = Recurrence(\n",
    "    state_variables={step.h_new:step.h_prev, step.c_new:step.c_prev, \n",
    "                     step.next_emb:step.inp, step.next_dur:step.dur_inp},\n",
    "    tracked_outputs=[step.next_token_probas,step.next_dur, step.next_token],\n",
    "    batch_size=theano.shared(1),\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/agentnet/utils/logging.py:14: UserWarning: [Verbose>=2] Recurrent loop without unroll_scan got nonempty random state updates list. That happened because there is some source of randomness (e.g. dropout) inside recurrent step graph. To compile such graph, one must either call .get_automatic_updates() right after .get_output and pass these updates to a function when compiling theano.function.\n",
      "  default_warn(\"[Verbose>=%s] %s\"%(verbosity_level,message),**kwargs)\n"
     ]
    }
   ],
   "source": [
    "generated_tokens, generated_durs = get_output(feedback_loop[step.next_token, step.next_dur])\n",
    "\n",
    "generated_music = T.stack([generated_tokens[0],generated_durs[0].reshape((-1,1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_sample = theano.function([n_steps],[generated_tokens[0], generated_durs[0]],updates=feedback_loop.get_automatic_updates(),allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_music(n_steps = dataset_generation.SEQ_LEN):\n",
    "    tok, durss = generate_sample(n_steps)\n",
    "    return np.hstack([tok,np.abs(durss.reshape((-1,1)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from midi_preproc import save_mat2_mid\n",
    "save_mat2_mid(gen_music())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "#train loop\n",
    "t = tqdm_notebook(dataset_generation.iterate_minibatches(1000, 1000), total = 1000)\n",
    "\n",
    "categ_hist = []\n",
    "reg_hist = []\n",
    "\n",
    "it = 1\n",
    "for batch in t:\n",
    "    notes = batch[:,:-1]\n",
    "    print \"Begin\"\n",
    "    durations = np.array( batch[:,-1].todense()).ravel()\n",
    "    categ, reg = train_step(notes, durations)\n",
    "    print \"Done\"\n",
    "    categ_hist.append(categ.mean())\n",
    "    reg_hist.append(reg.mean())\n",
    "    it+=1\n",
    "    if it%3 == 0:\n",
    "        clear_output()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(categ_hist)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(reg_hist)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "87aff51375a749b893cad67936ca2cdf": {
     "views": [
      {
       "cell_index": 26
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
